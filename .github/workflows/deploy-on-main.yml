# A4: Hybrid â€” CodeStar + GitHub Actions
# CodeStar triggers BOTH pipelines on every push (triggerOnPush: true).
# This workflow adds intelligence: it detects what changed and stops
# the unnecessary pipeline to avoid wasted builds.
#
# See: docs/design-decisions/DDR-055-deployment-automation.md

name: Intelligent Pipeline Trigger

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      pipeline:
        description: "Which pipeline(s) to trigger"
        required: true
        type: choice
        options:
          - auto-detect
          - backend-only
          - frontend-only
          - both

permissions:
  contents: read

env:
  AWS_REGION: us-east-1
  BACKEND_PIPELINE: AiSocialMediaBackendPipeline
  FRONTEND_PIPELINE: AiSocialMediaFrontendPipeline

jobs:
  detect-changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.changes.outputs.backend }}
      frontend: ${{ steps.changes.outputs.frontend }}
      scope: ${{ steps.changes.outputs.scope }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for diffing against last deployed commit

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Analyze changed files
        id: changes
        run: |
          # For workflow_dispatch, respect the manual choice
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            case "${{ inputs.pipeline }}" in
              backend-only)
                echo "backend=true" >> "$GITHUB_OUTPUT"
                echo "frontend=false" >> "$GITHUB_OUTPUT"
                echo "scope=backend-only" >> "$GITHUB_OUTPUT"
                ;;
              frontend-only)
                echo "backend=false" >> "$GITHUB_OUTPUT"
                echo "frontend=true" >> "$GITHUB_OUTPUT"
                echo "scope=frontend-only" >> "$GITHUB_OUTPUT"
                ;;
              both)
                echo "backend=true" >> "$GITHUB_OUTPUT"
                echo "frontend=true" >> "$GITHUB_OUTPUT"
                echo "scope=both" >> "$GITHUB_OUTPUT"
                ;;
              auto-detect)
                ;; # Fall through to auto-detection below
            esac
            # Exit early if not auto-detect
            if [ "${{ inputs.pipeline }}" != "auto-detect" ]; then
              exit 0
            fi
          fi

          # Query the last successfully deployed commit for each pipeline.
          # This avoids the HEAD~1 pitfall where batched pushes or sequential
          # backend-only commits cause frontend changes to be silently skipped.
          get_last_deployed_commit() {
            local pipeline_name=$1
            aws codepipeline list-pipeline-executions \
              --pipeline-name "$pipeline_name" \
              --max-results 20 \
              --query 'pipelineExecutionSummaries[?status==`Succeeded`] | [0].sourceRevisions[0].revisionId' \
              --output text 2>/dev/null || echo ""
          }

          BE_LAST=$(get_last_deployed_commit "$BACKEND_PIPELINE")
          FE_LAST=$(get_last_deployed_commit "$FRONTEND_PIPELINE")
          echo "Last deployed backend commit: ${BE_LAST:-unknown}"
          echo "Last deployed frontend commit: ${FE_LAST:-unknown}"

          BACKEND=false
          FRONTEND=false

          # Diff HEAD against each pipeline's last deployed commit.
          # If a pipeline has never succeeded, treat it as needing deployment.
          if [ -n "$BE_LAST" ] && [ "$BE_LAST" != "None" ] && git cat-file -t "$BE_LAST" >/dev/null 2>&1; then
            BE_CHANGED=$(git diff --name-only "$BE_LAST" HEAD 2>/dev/null || echo "")
          else
            BE_CHANGED=$(git diff --name-only HEAD)
            echo "Backend baseline unknown â€” treating all files as changed"
          fi

          if [ -n "$FE_LAST" ] && [ "$FE_LAST" != "None" ] && git cat-file -t "$FE_LAST" >/dev/null 2>&1; then
            FE_CHANGED=$(git diff --name-only "$FE_LAST" HEAD 2>/dev/null || echo "")
          else
            FE_CHANGED=$(git diff --name-only HEAD)
            echo "Frontend baseline unknown â€” treating all files as changed"
          fi

          echo ""
          echo "=== Files changed since last backend deploy ==="
          echo "$BE_CHANGED"
          echo ""
          echo "=== Files changed since last frontend deploy ==="
          echo "$FE_CHANGED"
          echo ""

          if echo "$BE_CHANGED" | grep -qE '^(cmd/|internal/|go\.(mod|sum)$|.*Dockerfile)'; then
            BACKEND=true
          fi

          if echo "$FE_CHANGED" | grep -qE '^web/'; then
            FRONTEND=true
          fi

          # Determine scope
          if [ "$BACKEND" = "true" ] && [ "$FRONTEND" = "true" ]; then
            SCOPE="both"
          elif [ "$BACKEND" = "true" ]; then
            SCOPE="backend-only"
          elif [ "$FRONTEND" = "true" ]; then
            SCOPE="frontend-only"
          else
            SCOPE="none"
          fi

          echo "backend=$BACKEND" >> "$GITHUB_OUTPUT"
          echo "frontend=$FRONTEND" >> "$GITHUB_OUTPUT"
          echo "scope=$SCOPE" >> "$GITHUB_OUTPUT"

          echo ""
          echo "=== Detection result ==="
          echo "Backend changed: $BACKEND"
          echo "Frontend changed: $FRONTEND"
          echo "Scope: $SCOPE"

  manage-pipelines:
    name: Manage Pipelines (${{ needs.detect-changes.outputs.scope }})
    runs-on: ubuntu-latest
    needs: detect-changes
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Handle pipeline executions
        id: pipelines
        env:
          BACKEND_CHANGED: ${{ needs.detect-changes.outputs.backend }}
          FRONTEND_CHANGED: ${{ needs.detect-changes.outputs.frontend }}
          SCOPE: ${{ needs.detect-changes.outputs.scope }}
        run: |
          echo "=== Pipeline Management ==="
          echo "Scope: $SCOPE | Backend changed: $BACKEND_CHANGED | Frontend changed: $FRONTEND_CHANGED"
          echo ""

          # Track outcomes for the summary step
          BACKEND_RESULT="n/a"
          FRONTEND_RESULT="n/a"

          # Helper: stop the most recent execution of a pipeline
          # Sets STOP_RESULT: stopped | not_triggered | no_execution | failed
          stop_pipeline() {
            local pipeline_name=$1
            local reason=$2
            STOP_RESULT=""

            echo "::group::Polling $pipeline_name for new execution"

            # Record the current latest execution BEFORE CodeStar triggers
            local before_id
            before_id=$(aws codepipeline list-pipeline-executions \
              --pipeline-name "$pipeline_name" \
              --max-results 1 \
              --query 'pipelineExecutionSummaries[0].pipelineExecutionId' \
              --output text 2>/dev/null || echo "NONE")
            echo "Baseline execution: $before_id"

            # Poll for a new CodeStar-triggered execution (up to ~40s)
            local exec_id="" exec_status=""
            local max_polls=4 poll_interval=10
            for i in $(seq 1 $max_polls); do
              sleep $poll_interval
              exec_id=$(aws codepipeline list-pipeline-executions \
                --pipeline-name "$pipeline_name" \
                --max-results 1 \
                --query 'pipelineExecutionSummaries[0].pipelineExecutionId' \
                --output text 2>/dev/null)
              exec_status=$(aws codepipeline list-pipeline-executions \
                --pipeline-name "$pipeline_name" \
                --max-results 1 \
                --query 'pipelineExecutionSummaries[0].status' \
                --output text 2>/dev/null)
              echo "Poll $i/$max_polls: id=$exec_id status=$exec_status"

              # Break early if a new execution appeared or existing one is now InProgress
              if [ "$exec_id" != "$before_id" ] && [ -n "$exec_id" ] && [ "$exec_id" != "None" ]; then
                break
              fi
              if [ "$exec_status" = "InProgress" ]; then
                break
              fi
            done

            echo "::endgroup::"

            # No execution at all
            if [ "$exec_id" = "None" ] || [ -z "$exec_id" ]; then
              echo "::notice::$pipeline_name: no execution exists, nothing to stop"
              STOP_RESULT="no_execution"
              return 0
            fi

            # No new execution and existing one isn't in-progress
            if [ "$exec_id" = "$before_id" ] && [ "$exec_status" != "InProgress" ]; then
              echo "::notice::$pipeline_name: no new execution was triggered (latest: $exec_status), nothing to stop"
              STOP_RESULT="not_triggered"
              return 0
            fi

            # New or in-progress execution found â€” stop it
            if [ "$exec_status" = "InProgress" ] || [ "$exec_status" = "Stopping" ]; then
              if aws codepipeline stop-pipeline-execution \
                --pipeline-name "$pipeline_name" \
                --pipeline-execution-id "$exec_id" \
                --abandon \
                --reason "$reason" 2>/dev/null; then
                echo "::notice::$pipeline_name: stopped execution $exec_id"
                STOP_RESULT="stopped"
              else
                echo "::error::$pipeline_name: FAILED to stop execution $exec_id"
                STOP_RESULT="failed"
                return 1
              fi
            else
              echo "::notice::$pipeline_name: execution already $exec_status, no stop needed"
              STOP_RESULT="not_triggered"
            fi
          }

          # Helper: start a pipeline manually (for workflow_dispatch)
          # Sets START_RESULT: started | failed
          start_pipeline() {
            local pipeline_name=$1
            START_RESULT=""
            local new_exec_id
            if new_exec_id=$(aws codepipeline start-pipeline-execution \
              --pipeline-name "$pipeline_name" \
              --query 'pipelineExecutionId' \
              --output text); then
              echo "::notice::$pipeline_name: started execution $new_exec_id"
              START_RESULT="started"
            else
              echo "::error::$pipeline_name: FAILED to start pipeline"
              START_RESULT="failed"
              return 1
            fi
          }

          # â”€â”€ Push events: CodeStar triggers both pipelines. Stop the unnecessary one(s). â”€â”€
          if [ "${{ github.event_name }}" = "push" ]; then
            case "$SCOPE" in
              frontend-only)
                stop_pipeline "$BACKEND_PIPELINE" "GH Actions: frontend-only change, no backend rebuild needed"
                BACKEND_RESULT="stop:$STOP_RESULT"
                FRONTEND_RESULT="running"
                ;;
              backend-only)
                stop_pipeline "$FRONTEND_PIPELINE" "GH Actions: backend-only change, no frontend rebuild needed"
                FRONTEND_RESULT="stop:$STOP_RESULT"
                BACKEND_RESULT="running"
                ;;
              both)
                echo "::notice::Both changed â€” letting both pipelines run (CodeStar triggered)"
                BACKEND_RESULT="running"
                FRONTEND_RESULT="running"
                ;;
              none)
                stop_pipeline "$BACKEND_PIPELINE" "GH Actions: no backend/frontend changes (docs/config only)"
                BACKEND_RESULT="stop:$STOP_RESULT"
                stop_pipeline "$FRONTEND_PIPELINE" "GH Actions: no backend/frontend changes (docs/config only)"
                FRONTEND_RESULT="stop:$STOP_RESULT"
                ;;
            esac
          fi

          # â”€â”€ Manual dispatch: start the selected pipeline(s). â”€â”€
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            if [ "$BACKEND_CHANGED" = "true" ]; then
              start_pipeline "$BACKEND_PIPELINE"
              BACKEND_RESULT="start:$START_RESULT"
            fi
            if [ "$FRONTEND_CHANGED" = "true" ]; then
              start_pipeline "$FRONTEND_PIPELINE"
              FRONTEND_RESULT="start:$START_RESULT"
            fi
          fi

          # Export results for the summary step
          echo "backend_result=$BACKEND_RESULT" >> "$GITHUB_OUTPUT"
          echo "frontend_result=$FRONTEND_RESULT" >> "$GITHUB_OUTPUT"

      - name: Summary
        if: always()
        env:
          SCOPE: ${{ needs.detect-changes.outputs.scope }}
          BACKEND_RESULT: ${{ steps.pipelines.outputs.backend_result }}
          FRONTEND_RESULT: ${{ steps.pipelines.outputs.frontend_result }}
        run: |
          # Map result codes to human-friendly labels with status icons
          format_result() {
            case "$1" in
              running)              echo "ðŸŸ¢ Running (CodeStar)" ;;
              stop:stopped)         echo "ðŸ”´ Stopped" ;;
              stop:not_triggered)   echo "âšª Not triggered (no stop needed)" ;;
              stop:no_execution)    echo "âšª No execution found" ;;
              stop:failed)          echo "âŒ Stop FAILED" ;;
              start:started)        echo "ðŸŸ¢ Started (manual)" ;;
              start:failed)         echo "âŒ Start FAILED" ;;
              n/a)                  echo "âšª N/A" ;;
              *)                    echo "â“ Unknown ($1)" ;;
            esac
          }

          BE=$(format_result "$BACKEND_RESULT")
          FE=$(format_result "$FRONTEND_RESULT")

          # Determine overall status
          if echo "$BACKEND_RESULT $FRONTEND_RESULT" | grep -q "failed"; then
            OVERALL="âŒ Completed with errors"
          else
            OVERALL="âœ… Completed successfully"
          fi

          {
            echo "## Pipeline Trigger Summary"
            echo ""
            echo "**Status: $OVERALL**"
            echo ""
            echo "| Property | Value |"
            echo "|----------|-------|"
            echo "| **Trigger** | \`${{ github.event_name }}\` |"
            echo "| **Commit** | \`${{ github.sha }}\` |"
            echo "| **Scope** | \`$SCOPE\` |"
            echo "| **Backend pipeline** | $BE |"
            echo "| **Frontend pipeline** | $FE |"
          } >> "$GITHUB_STEP_SUMMARY"

  verify-deployment:
    name: Verify Deployment
    runs-on: ubuntu-latest
    needs: [detect-changes, manage-pipelines]
    if: needs.detect-changes.outputs.scope != 'none'
    timeout-minutes: 35
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Wait for pipeline completion
        id: wait
        env:
          BACKEND_CHANGED: ${{ needs.detect-changes.outputs.backend }}
          FRONTEND_CHANGED: ${{ needs.detect-changes.outputs.frontend }}
        run: |
          echo "=== Deployment Verification ==="
          echo "Backend to verify: $BACKEND_CHANGED | Frontend to verify: $FRONTEND_CHANGED"
          echo ""

          MAX_POLLS=60       # 60 * 30s = 30 minutes
          POLL_INTERVAL=30   # seconds between polls

          # Helper: wait for a pipeline execution to reach a terminal state.
          # Returns 0 on Succeeded, 1 on Failed/Stopped/timeout.
          wait_for_pipeline() {
            local pipeline_name=$1

            echo "::group::Waiting for $pipeline_name"

            # Find the latest execution
            local exec_id exec_status
            exec_id=$(aws codepipeline list-pipeline-executions \
              --pipeline-name "$pipeline_name" \
              --max-results 1 \
              --query 'pipelineExecutionSummaries[0].pipelineExecutionId' \
              --output text 2>/dev/null)
            exec_status=$(aws codepipeline list-pipeline-executions \
              --pipeline-name "$pipeline_name" \
              --max-results 1 \
              --query 'pipelineExecutionSummaries[0].status' \
              --output text 2>/dev/null)

            echo "Tracking execution: $exec_id (initial status: $exec_status)"

            if [ -z "$exec_id" ] || [ "$exec_id" = "None" ]; then
              echo "::endgroup::"
              echo "::error::$pipeline_name: no execution found to verify"
              return 1
            fi

            # Check if already terminal
            case "$exec_status" in
              Succeeded)
                echo "::endgroup::"
                echo "::notice::$pipeline_name: already Succeeded ($exec_id)"
                return 0 ;;
              Failed|Stopped)
                echo "::endgroup::"
                echo "::error::$pipeline_name: already $exec_status ($exec_id)"
                return 1 ;;
            esac

            # Poll until terminal
            for i in $(seq 1 $MAX_POLLS); do
              sleep $POLL_INTERVAL
              exec_status=$(aws codepipeline list-pipeline-executions \
                --pipeline-name "$pipeline_name" \
                --max-results 1 \
                --query 'pipelineExecutionSummaries[0].status' \
                --output text 2>/dev/null)
              local elapsed=$((i * POLL_INTERVAL))
              echo "Poll $i/$MAX_POLLS: status=$exec_status (${elapsed}s elapsed)"

              case "$exec_status" in
                Succeeded)
                  echo "::endgroup::"
                  echo "::notice::$pipeline_name: Succeeded ($exec_id) after ${elapsed}s"
                  return 0 ;;
                Failed|Stopped)
                  echo "::endgroup::"
                  echo "::error::$pipeline_name: $exec_status ($exec_id) after ${elapsed}s"
                  # Auto-diagnose: dump failed stage details and CodeBuild logs
                  echo "::group::Failure diagnosis for $pipeline_name"
                  echo "=== Stage details ==="
                  aws codepipeline list-action-executions \
                    --pipeline-name "$pipeline_name" \
                    --filter "pipelineExecutionId=$exec_id" \
                    --query 'actionExecutionDetails[?status==`Failed`].{action:actionName,stage:stageName,summary:output.executionResult.externalExecutionSummary,buildId:output.executionResult.externalExecutionId}' \
                    --output json 2>/dev/null || true
                  # Fetch last 50 lines of CodeBuild logs for each failed action
                  for build_id in $(aws codepipeline list-action-executions \
                    --pipeline-name "$pipeline_name" \
                    --filter "pipelineExecutionId=$exec_id" \
                    --query 'actionExecutionDetails[?status==`Failed`].output.executionResult.externalExecutionId' \
                    --output text 2>/dev/null); do
                    project_name=$(echo "$build_id" | cut -d: -f1)
                    stream_id=$(echo "$build_id" | cut -d: -f2)
                    echo "=== CodeBuild logs: $build_id (last 50 events) ==="
                    aws logs filter-log-events \
                      --log-group-name "/aws/codebuild/$project_name" \
                      --log-stream-names "$stream_id" \
                      --query 'events[-50:].message' \
                      --output text 2>/dev/null || echo "(unable to fetch logs)"
                  done
                  echo "::endgroup::"
                  return 1 ;;
              esac
            done

            echo "::endgroup::"
            echo "::error::$pipeline_name: timed out after $((MAX_POLLS * POLL_INTERVAL))s ($exec_id)"
            return 1
          }

          OVERALL=0
          BE_STATUS="skipped"
          FE_STATUS="skipped"

          if [ "$BACKEND_CHANGED" = "true" ]; then
            if wait_for_pipeline "$BACKEND_PIPELINE"; then
              BE_STATUS="Succeeded"
            else
              BE_STATUS="Failed"
              OVERALL=1
            fi
          fi

          if [ "$FRONTEND_CHANGED" = "true" ]; then
            if wait_for_pipeline "$FRONTEND_PIPELINE"; then
              FE_STATUS="Succeeded"
            else
              FE_STATUS="Failed"
              OVERALL=1
            fi
          fi

          echo "backend_status=$BE_STATUS" >> "$GITHUB_OUTPUT"
          echo "frontend_status=$FE_STATUS" >> "$GITHUB_OUTPUT"

          exit $OVERALL

      - name: Deployment Summary
        if: always()
        env:
          BE_STATUS: ${{ steps.wait.outputs.backend_status }}
          FE_STATUS: ${{ steps.wait.outputs.frontend_status }}
        run: |
          format_deploy() {
            case "$1" in
              Succeeded) echo "âœ… Succeeded" ;;
              Failed)    echo "âŒ Failed" ;;
              skipped)   echo "â­ï¸ Skipped (no changes)" ;;
              *)         echo "â“ Unknown ($1)" ;;
            esac
          }

          BE=$(format_deploy "$BE_STATUS")
          FE=$(format_deploy "$FE_STATUS")

          if [ "$BE_STATUS" = "Failed" ] || [ "$FE_STATUS" = "Failed" ]; then
            OVERALL="âŒ Deployment failed"
          else
            OVERALL="âœ… Deployment succeeded"
          fi

          {
            echo "## Deployment Verification"
            echo ""
            echo "**Status: $OVERALL**"
            echo ""
            echo "| Pipeline | Result |"
            echo "|----------|--------|"
            echo "| **Backend** | $BE |"
            echo "| **Frontend** | $FE |"
          } >> "$GITHUB_STEP_SUMMARY"
